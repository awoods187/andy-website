#!/usr/bin/env python3
"""
Scrape Cockroach Labs Blog Posts

Scrapes Andy Woods' author page on cockroachlabs.com to extract
all blog posts with metadata (title, URL, date, image, excerpt).
Generates a TypeScript data file for use in the Astro site.
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime
import json
import re

def scrape_crl_author_page():
    """
    Scrape the CRL author page and extract blog post metadata.
    """
    url = "https://www.cockroachlabs.com/author/andy-woods/"

    print(f"Fetching {url}...")
    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.content, 'html.parser')
    posts = []

    # Find all blog post cards
    # Note: This selector may need adjustment based on actual HTML structure
    post_cards = soup.find_all('article') or soup.find_all('div', class_=re.compile('post|article|card'))

    print(f"Found {len(post_cards)} potential post elements")

    for card in post_cards:
        try:
            # Extract title and URL
            title_elem = card.find('h2') or card.find('h3') or card.find('a')
            if not title_elem:
                continue

            title = title_elem.get_text(strip=True)

            # Find link
            link_elem = card.find('a', href=True)
            if not link_elem:
                continue

            url = link_elem['href']
            if not url.startswith('http'):
                url = f"https://www.cockroachlabs.com{url}"

            # Extract image
            img_elem = card.find('img')
            image_url = img_elem['src'] if img_elem and 'src' in img_elem.attrs else None
            if image_url and not image_url.startswith('http'):
                image_url = f"https://www.cockroachlabs.com{image_url}"

            # Extract excerpt/description
            excerpt_elem = card.find('p') or card.find('div', class_=re.compile('excerpt|description|summary'))
            excerpt = excerpt_elem.get_text(strip=True) if excerpt_elem else ""

            # Extract date
            date_elem = card.find('time') or card.find('span', class_=re.compile('date'))
            date_str = date_elem.get_text(strip=True) if date_elem else None

            # Try to parse date
            published_date = None
            if date_str:
                try:
                    # Try various date formats
                    for fmt in ['%B %d, %Y', '%b %d, %Y', '%Y-%m-%d', '%m/%d/%Y']:
                        try:
                            published_date = datetime.strptime(date_str, fmt).strftime('%Y-%m-%d')
                            break
                        except ValueError:
                            continue
                except Exception as e:
                    print(f"Could not parse date '{date_str}': {e}")

            if title and url:
                post = {
                    'title': title,
                    'url': url,
                    'date': published_date,
                    'image': image_url,
                    'excerpt': excerpt[:200] if excerpt else "",  # Limit excerpt length
                }
                posts.append(post)
                print(f"✓ Extracted: {title}")

        except Exception as e:
            print(f"Error processing card: {e}")
            continue

    return posts

def generate_typescript_file(posts):
    """
    Generate a TypeScript data file from the scraped posts.
    """
    ts_content = '''/**
 * Cockroach Labs Blog Posts
 *
 * External blog posts written for Cockroach Labs.
 * Auto-generated by scripts/scrape-crl-posts.py
 * Last updated: {timestamp}
 */

export interface ExternalPost {{
  title: string;
  url: string;
  date: string;
  image: string | null;
  excerpt: string;
  source: 'cockroach-labs';
}}

export const crlPosts: ExternalPost[] = {posts_json};
'''.format(
        timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        posts_json=json.dumps(posts, indent=2)
    )

    return ts_content

def main():
    print("=" * 60)
    print("Scraping Cockroach Labs Author Page")
    print("=" * 60)

    # Scrape posts
    posts = scrape_crl_author_page()

    if not posts:
        print("\n❌ No posts found! The page structure may have changed.")
        print("Please check the HTML structure and update selectors.")
        return

    print(f"\n✅ Successfully extracted {len(posts)} posts")

    # Generate TypeScript file
    ts_content = generate_typescript_file(posts)

    output_path = 'src/data/crl-posts.ts'
    with open(output_path, 'w') as f:
        f.write(ts_content)

    print(f"\n✅ Generated {output_path}")
    print("\nPosts extracted:")
    for post in posts:
        print(f"  - {post['title']}")
        print(f"    Date: {post['date'] or 'Unknown'}")
        print(f"    Image: {'✓' if post['image'] else '✗'}")
        print()

if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        print(f"\n❌ Error: {e}")
        import traceback
        traceback.print_exc()
